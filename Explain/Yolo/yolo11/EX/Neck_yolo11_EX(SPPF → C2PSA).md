
# ğŸ”„ Luá»“ng xá»­ lÃ½ tá»« SPPF â†’ C2PSA trong YOLOv11

![](../imgs/C2PSA.jpg)

## 1. Äáº§u ra tá»« **SPPF [1024, 5]**
- **KÃ­ch thÆ°á»›c khÃ´ng gian**: Váº«n lÃ  **20x20**.
- **Sá»‘ kÃªnh**: **1024 kÃªnh**.
- **HÃ¬nh dáº¡ng tensor**: `[N, 1024, 20, 20]`.
- **Äáº·c Ä‘iá»ƒm**: Äáº·c trÆ°ng Ä‘Ã£ Ä‘Æ°á»£c tÄƒng cÆ°á»ng vá»›i **receptive field rá»™ng hÆ¡n** nhá» 3 láº§n max pooling trong SPPF.

---

## 2. VÃ o **C2PSA [c1=1024, c2=1024, n=1, e=0.5]**
- **C2PSA** trong YOLOv11 lÃ  má»™t khá»‘i tá»‘i Æ°u hÃ³a, sá»­ dá»¥ng **PSA (Partial Self-Attention)** Ä‘á»ƒ káº¿t há»£p hiá»‡u quáº£ giá»¯a Ä‘áº·c trÆ°ng cá»¥c bá»™ vÃ  toÃ n cá»¥c.
- **Tham sá»‘**:
  - `c1`: Sá»‘ kÃªnh Ä‘áº§u vÃ o (1024, khá»›p vá»›i Ä‘áº§u ra cá»§a SPPF).
  - `c2`: Sá»‘ kÃªnh Ä‘áº§u ra (1024, giá»¯ nguyÃªn sá»‘ kÃªnh).
  - `n`: Sá»‘ lÆ°á»£ng `PSABlock` (máº·c Ä‘á»‹nh lÃ  1).
  - `e`: Tá»· lá»‡ má»Ÿ rá»™ng (máº·c Ä‘á»‹nh lÃ  0.5, tá»©c giáº£m sá»‘ kÃªnh xuá»‘ng má»™t ná»­a trong nhÃ¡nh chÃ­nh).
- **Cáº¥u trÃºc** (dá»±a trÃªn `__init__`):
  1. `self.c = int(c1 * e)`: Sá»‘ kÃªnh trung gian, vá»›i `e=0.5`, nÃªn `self.c = int(1024 * 0.5) = 512`.
  2. `self.cv1 = Conv(c1, 2 * self.c, 1, 1)`: Conv 1x1 tÄƒng sá»‘ kÃªnh tá»« 1024 lÃªn `2 * 512 = 1024`.
  3. `self.cv2 = Conv(2 * self.c, c1, 1)`: Conv 1x1 nÃ©n láº¡i tá»« 1024 vá» 1024.
  4. `self.m`: Má»™t `nn.Sequential` chá»©a `n` khá»‘i `PSABlock`, má»—i khá»‘i cÃ³:
     - `attn_ratio=0.5`: Tá»· lá»‡ kÃ­ch thÆ°á»›c Query/Key so vá»›i Value.
     - `num_heads=self.c // 64`: Sá»‘ head trong multi-head attention, vá»›i `self.c = 512`, nÃªn `num_heads = 512 // 64 = 8`.

### Ã nghÄ©a cá»§a PSABlock
- `PSABlock` lÃ  má»™t biáº¿n thá»ƒ cá»§a self-attention, Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ giáº£m chi phÃ­ tÃ­nh toÃ¡n so vá»›i attention thÃ´ng thÆ°á»ng, Ä‘á»“ng thá»i giá»¯ kháº£ nÄƒng mÃ´ hÃ¬nh hÃ³a quan há»‡ khÃ´ng gian.
- Vá»›i `attn_ratio=0.5` vÃ  `num_heads=8`, má»—i head xá»­ lÃ½ má»™t pháº§n Ä‘áº·c trÆ°ng, táº­p trung vÃ o cÃ¡c má»‘i quan há»‡ quan trá»ng trong khÃ´ng gian 20x20.

---

## 3. Äáº§u ra cá»§a **C2PSA**
- **KÃ­ch thÆ°á»›c khÃ´ng gian**: Váº«n lÃ  **20x20**, vÃ¬ cÃ¡c phÃ©p biáº¿n Ä‘á»•i (Conv 1x1, attention) khÃ´ng thay Ä‘á»•i kÃ­ch thÆ°á»›c khÃ´ng gian.
- **Sá»‘ kÃªnh**: Váº«n lÃ  **1024**, nhÆ° Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trong `c2`.
- **HÃ¬nh dáº¡ng tensor**: `[N, 1024, 20, 20]`.
- **Äáº·c Ä‘iá»ƒm**: Äáº·c trÆ°ng Ä‘Æ°á»£c tinh chá»‰nh vá»›i **partial self-attention**, giÃºp mÃ´ hÃ¬nh táº­p trung vÃ o cÃ¡c vÃ¹ng quan trá»ng trong khÃ´ng gian mÃ  khÃ´ng tÄƒng quÃ¡ má»©c chi phÃ­ tÃ­nh toÃ¡n.

---

# ğŸ“Š TÃ³m táº¯t pipeline tá»« SPPF â†’ C2PSA
```
Input (20Ã—20Ã—1024)
   â†“ SPPF [1024, 5]
Tensor (20Ã—20Ã—1024, receptive field â†‘)
   â†“ C2PSA [1024, 1024, n=1, e=0.5]
Tensor (20Ã—20Ã—1024, vá»›i partial self-attention)
```

---

# ğŸ§  Ã nghÄ©a khi ghÃ©p SPPF â†’ C2PSA
- **SPPF**: Cung cáº¥p **bá»‘i cáº£nh toÃ n cá»¥c** báº±ng cÃ¡ch má»Ÿ rá»™ng receptive field, giÃºp mÃ´ hÃ¬nh "nhÃ¬n" toÃ n bá»™ vÃ¹ng áº£nh.
- **C2PSA**: Tinh chá»‰nh Ä‘áº·c trÆ°ng vá»›i **partial self-attention**, táº­p trung vÃ o cÃ¡c vÃ¹ng quan trá»ng (nhÆ° Ä‘á»‘i tÆ°á»£ng) mÃ  váº«n giá»¯ hiá»‡u quáº£ tÃ­nh toÃ¡n nhá» `attn_ratio=0.5` vÃ  sá»‘ head giá»›i háº¡n.
- **Káº¿t há»£p**: SPPF mang láº¡i cÃ¡i nhÃ¬n rá»™ng, C2PSA tÄƒng cÆ°á»ng kháº£ nÄƒng táº­p trung vÃ o chi tiáº¿t quan trá»ng, tá»‘i Æ°u cho viá»‡c phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng.

VÃ­ dá»¥ hÃ¬nh dung:
- SPPF = "NhÃ¬n toÃ n cáº£nh ngÃ´i nhÃ  Ä‘á»ƒ Ä‘á»‹nh vá»‹ cá»­a sá»•."
- C2PSA = "ChÃº Ã½ ká»¹ vÃ o cá»­a sá»•, táº­p trung vÃ o cÃ¡c chi tiáº¿t quan trá»ng nhÆ° khung hoáº·c kÃ­nh, nhÆ°ng khÃ´ng quÃ¡ tá»‘n tÃ i nguyÃªn."

---

# ğŸ” PhÃ¢n tÃ­ch code vÃ  dÃ²ng cháº£y dá»¯ liá»‡u

### `__init__`
```python
def __init__(self, c1: int, c2: int, n: int = 1, e: float = 0.5):
    super().__init__()
    assert c1 == c2  # Äáº£m báº£o sá»‘ kÃªnh vÃ o = sá»‘ kÃªnh ra
    self.c = int(c1 * e)  # Sá»‘ kÃªnh trung gian (1024 * 0.5 = 512)
    self.cv1 = Conv(c1, 2 * self.c, 1, 1)  # TÄƒng kÃªnh lÃªn 1024
    self.cv2 = Conv(2 * self.c, c1, 1)  # NÃ©n láº¡i vá» 1024
    self.m = nn.Sequential(*(PSABlock(self.c, attn_ratio=0.5, num_heads=self.c // 64) for _ in range(n)))
```

### `forward`
```python
def forward(self, x: torch.Tensor) -> torch.Tensor:
    a, b = self.cv1(x).split((self.c, self.c), dim=1)  # Chia thÃ nh [N, 512, 20, 20] vÃ  [N, 512, 20, 20]
    b = self.m(b)  # Xá»­ lÃ½ nhÃ¡nh b qua PSABlock
    return self.cv2(torch.cat((a, b), 1))  # Concat vÃ  nÃ©n láº¡i [N, 1024, 20, 20]
```

### DÃ²ng cháº£y dá»¯ liá»‡u
- **Input**: `[N, 1024, 20, 20]` (tá»« SPPF).
- **BÆ°á»›c 1**: `cv1(x)` â†’ `[N, 1024, 20, 20]`, sau Ä‘Ã³ `split` thÃ nh:
  - `a`: `[N, 512, 20, 20]` (nhÃ¡nh giá»¯ nguyÃªn).
  - `b`: `[N, 512, 20, 20]` (nhÃ¡nh Ä‘i qua PSABlock).
- **BÆ°á»›c 2**: `self.m(b)` â†’ `[N, 512, 20, 20]`, xá»­ lÃ½ qua 1 `PSABlock` vá»›i attention.
- **BÆ°á»›c 3**: `torch.cat((a, b), 1)` â†’ `[N, 1024, 20, 20]`.
- **BÆ°á»›c 4**: `cv2(...)` â†’ `[N, 1024, 20, 20]` (Ä‘áº§u ra cuá»‘i cÃ¹ng).

---

# âœ… Ã nghÄ©a Ä‘áº§u ra
- **KÃ­ch thÆ°á»›c khÃ´ng gian**: Váº«n **20x20**.
- **Sá»‘ kÃªnh**: Váº«n **1024**.
- **Cáº£i tiáº¿n**: ThÃªm **partial self-attention** qua `PSABlock`, giÃºp mÃ´ hÃ¬nh táº­p trung vÃ o cÃ¡c vÃ¹ng quan trá»ng vá»›i chi phÃ­ tÃ­nh toÃ¡n tá»‘i Æ°u.

---

# ğŸ’¡ Ghi chÃº thÃªm
- MÃ£ nguá»“n má»›i pháº£n Ã¡nh thiáº¿t káº¿ nháº¹ nhÃ ng hÆ¡n cá»§a YOLOv11, táº­p trung vÃ o hiá»‡u quáº£ vá»›i `n=1` vÃ  `e=0.5`.
- Káº¿t quáº£ sau C2PSA cÃ³ thá»ƒ Ä‘i vÃ o cÃ¡c khá»‘i tiáº¿p theo (nhÆ° Ä‘áº§u ra hoáº·c lá»›p detect).

