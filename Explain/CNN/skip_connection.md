

# ğŸ”— Skip Connection (káº¿t ná»‘i táº¯t)

## 1. Ã nghÄ©a

* Skip connection = **ná»‘i táº¯t tá»« input sang output**, thay vÃ¬ chá»‰ qua nhiá»u lá»›p liÃªn tiáº¿p.
* CÃ´ng thá»©c:

$$
y = f(x) + x
$$

Trong Ä‘Ã³:

* $x$: input gá»‘c (Ä‘áº·c trÆ°ng ban Ä‘áº§u).
* $f(x)$: output sau khi qua khá»‘i xá»­ lÃ½ (Conv, Attention,â€¦).
* $y$: káº¿t quáº£ cuá»‘i cÃ¹ng sau khi cá»™ng.

---

## 2. Lá»£i Ã­ch chÃ­nh

### ğŸš€ Giá»¯ láº¡i thÃ´ng tin gá»‘c

Náº¿u Ä‘i qua nhiá»u lá»›p, Ä‘áº·c trÆ°ng cÃ³ thá»ƒ bá»‹ mÃ©o/máº¥t.
Skip connection giá»¯ láº¡i input Ä‘á»ƒ â€œbÆ¡m tháº³ngâ€ vÃ o output â†’ mÃ´ hÃ¬nh khÃ´ng quÃªn thÃ´ng tin ban Ä‘áº§u.

---

### ğŸš€ Giáº£m gradient vanish

Trong máº¡ng sÃ¢u, gradient dá»… bá»‹ tiÃªu biáº¿n.
Skip connection má»Ÿ má»™t â€œÄ‘Æ°á»ng táº¯tâ€ cho gradient quay ngÆ°á»£c láº¡i, giÃºp viá»‡c há»c á»•n Ä‘á»‹nh hÆ¡n.

---

### ğŸš€ Há»c pháº§n dÆ° (Residual Learning)

Máº¡ng khÃ´ng há»c toÃ n bá»™ Ã¡nh xáº¡ $H(x)$ ná»¯a, mÃ  chá»‰ há»c pháº§n dÆ°:

$$
H(x) = f(x) + x 
\quad \Rightarrow \quad
f(x) = H(x) - x
$$

â†’ Dá»… há»c hÆ¡n nhiá»u, vÃ¬ chá»‰ cáº§n â€œsá»­a lá»—iâ€ thay vÃ¬ xÃ¢y má»›i hoÃ n toÃ n.

---

### ğŸš€ Káº¿t há»£p nhiá»u má»©c Ä‘áº·c trÆ°ng

* $x$: Ä‘áº·c trÆ°ng thÃ´ (cáº¡nh, mÃ u).
* $f(x)$: Ä‘áº·c trÆ°ng cao (ngá»¯ cáº£nh, cáº¥u trÃºc).
* Khi cá»™ng láº¡i: vá»«a chi tiáº¿t, vá»«a ngá»¯ cáº£nh â†’ dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c hÆ¡n.

---

## 3. VÃ­ dá»¥ toÃ¡n há»c

### ğŸ”´ TrÆ°á»ng há»£p khÃ´ng cÃ³ skip connection

Giáº£ sá»­ muá»‘n máº¡ng há»c Ã¡nh xáº¡:

$$
H(x) = 2x
$$

Náº¿u báº¯t máº¡ng há»c trá»±c tiáº¿p $H(x)$, nÃ³ pháº£i tÃ¬m Ä‘Ãºng quy luáº­t gáº¥p Ä‘Ã´i.

---

### ğŸŸ¢ TrÆ°á»ng há»£p cÃ³ skip connection

Ta viáº¿t láº¡i:

$$
H(x) = f(x) + x
$$

Khi Ä‘Ã³:

$$
f(x) = H(x) - x = 2x - x = x
$$

ğŸ‘‰ Máº¡ng chá»‰ cáº§n há»c $f(x) = x$ (báº£n sao Ä‘Æ¡n giáº£n), thay vÃ¬ $H(x) = 2x$ (gáº¥p Ä‘Ã´i).
Dá»… dÃ ng hÆ¡n ráº¥t nhiá»u!

---

## 4. Trá»±c quan (vÃ­ dá»¥ hÃ¬nh áº£nh)

* Input $x$: áº£nh hÆ¡i má» â†’ Ä‘Ã£ chá»©a 80% thÃ´ng tin.
* Output mong muá»‘n $H(x)$: áº£nh rÃµ.
* Pháº§n dÆ° $f(x)$: chi tiáº¿t cÃ²n thiáº¿u (20% Ä‘á»™ nÃ©t).

Khi cÃ³ skip connection, máº¡ng **chá»‰ cáº§n há»c pháº§n chi tiáº¿t cÃ²n thiáº¿u** thay vÃ¬ pháº£i dá»±ng láº¡i toÃ n bá»™ áº£nh tá»« Ä‘áº§u.

---

## 5. TÃ³m gá»n

Skip connection giÃºp:

1. Giá»¯ thÃ´ng tin gá»‘c.
2. TrÃ¡nh gradient vanish.
3. Há»c pháº§n dÆ° â†’ nhanh & á»•n Ä‘á»‹nh hÆ¡n.
4. Káº¿t há»£p Ä‘áº·c trÆ°ng nhiá»u má»©c â†’ tÄƒng chÃ­nh xÃ¡c.

ğŸ‘‰ **Pháº§n dÆ° $f(x)$ chÃ­nh lÃ  nhá»¯ng gÃ¬ cáº§n thÃªm/sá»­a Ä‘á»ƒ biáº¿n input thÃ nh output mong muá»‘n.**

---




---

## 1. Äang cÃ³ hai â€œngá»¯ cáº£nhâ€

### Ngá»¯ cáº£nh A â€” **Code cháº¡y (forward)**

Máº¡ng cháº¡y tháº­t thÃ¬ nÃ³ chá»‰ biáº¿t tÃ­nh toÃ¡n:

$$
y = f(x) + x
$$

* $x$: input cá»§a block.
* $f(x)$: má»™t chuá»—i conv/bn/relu bÃªn trong block.
* $y$: output mÃ  block xuáº¥t ra.

---

### Ngá»¯ cáº£nh B â€” **LÃ½ thuyáº¿t há»c (target function)**

Khi ta thiáº¿t káº¿ máº¡ng, ta muá»‘n máº¡ng mÃ´ phá»ng **má»™t hÃ m mong muá»‘n** $H(x)$.

Vá»›i residual learning, ta giáº£ Ä‘á»‹nh:

$$
H(x) = f(x) + x
$$

* $H(x)$: mapping tháº­t mÃ  ta muá»‘n há»c (ground-truth).
* $f(x)$: pháº§n cÃ²n thiáº¿u (residual) mÃ  máº¡ng cáº§n há»c.

---

## 2. Má»‘i quan há»‡

* Trong **code**: ta luÃ´n tÃ­nh `y = f(x) + x`.
* Trong **phÃ¢n tÃ­ch**: ta so sÃ¡nh $y$ vá»›i $H(x)$.

Náº¿u $y$ khá»›p vá»›i $H(x)$, tá»©c lÃ  máº¡ng Ä‘Ã£ há»c Ä‘Æ°á»£c residual $f(x) = H(x) - x$.

---

## 3. VÃ­ dá»¥ minh há»a 

Giáº£ sá»­ ta muá»‘n há»c $H(x) = 2x$.

* **KhÃ´ng cÃ³ skip connection:**
  Máº¡ng pháº£i há»c trá»±c tiáº¿p $H(x) = 2x$.
  â†’ khÃ³ hÆ¡n.

* **CÃ³ skip connection:**
  Block xuáº¥t ra $y = f(x) + x$.
  Muá»‘n $y = 2x$, thÃ¬:

  $$
  f(x) = H(x) - x = 2x - x = x
  $$

  â†’ máº¡ng chá»‰ cáº§n há»c â€œcopy inputâ€ (Ä‘Æ¡n giáº£n hÆ¡n nhiá»u).

---

## 4. SÆ¡ Ä‘á»“ ASCII (Ä‘á»ƒ dá»… hÃ¬nh dung)

```
Input x -----> [ f(x) ] ---+
             (Conv/BN/ReLU) |
                            +---> y  (output)
             Skip ----------+
```

* Forward: `y = f(x) + x`.
* Target: ta muá»‘n `y â‰ˆ H(x)`.
* Do Ä‘Ã³, f(x) chá»‰ cáº§n há»c pháº§n **chÃªnh lá»‡ch** giá»¯a $H(x)$ vÃ  $x$.

---

ğŸ‘‰ NÃ³i ngáº¯n gá»n:

* `y = f(x) + x` lÃ  **cÃ¡ch tÃ­nh toÃ¡n trong máº¡ng**.
* `H(x) = f(x) + x` lÃ  **cÃ¡ch chÃºng ta diá»…n giáº£i bÃ i toÃ¡n há»c residual**.



---

## So sÃ¡nh há»c hÃ m $H(x) = 2x$

| TrÆ°á»ng há»£p          | CÃ´ng thá»©c output | Máº¡ng pháº£i há»c gÃ¬?                                         | Äá»™ khÃ³                                           |
| ------------------- | ---------------- | --------------------------------------------------------- | ------------------------------------------------ |
| âŒ **KhÃ´ng cÃ³ skip** | $y = f(x)$     | $f(x) = H(x) = 2x$ (pháº£i há»c toÃ n bá»™ phÃ©p nhÃ¢n Ä‘Ã´i)     | KhÃ³ hÆ¡n (máº¡ng pháº£i tÃ¡i táº¡o cáº£ hÃ m $2x$ tá»« Ä‘áº§u) |
| âœ… **CÃ³ skip**       | $y = f(x) + x$ | Muá»‘n $y = H(x) = 2x$ â‡’ $f(x) = H(x) - x = 2x - x = x$ | Dá»… hÆ¡n (chá»‰ cáº§n há»c â€œcopy inputâ€)                |

---

### Diá»…n giáº£i

* **KhÃ´ng skip:** mÃ´ hÃ¬nh pháº£i tÃ¬m ra cÃ¡ch biáº¿n $x$ thÃ nh $2x$ â†’ khÃ¡ tá»‘n cÃ´ng.
* **CÃ³ skip:** mÃ´ hÃ¬nh Ä‘Ã£ cÃ³ sáºµn $+x$ tá»« Ä‘Æ°á»ng táº¯t, nÃªn chá»‰ cáº§n há»c thÃªm pháº§n dÆ° $f(x) = x$ â†’ dá»… vÃ  nhanh há»™i tá»¥ hÆ¡n.

---

ğŸ‘‰ Váº­y **skip connection lÃ m bÃ i toÃ¡n trá»Ÿ nÃªn â€œdá»…â€ hÆ¡n**, vÃ¬ máº¡ng chá»‰ há»c **pháº§n thiáº¿u** thay vÃ¬ toÃ n bá»™ hÃ m.

